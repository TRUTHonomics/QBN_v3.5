import cupy as cp
import numpy as np
from typing import List, Tuple, Dict, Optional
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)


# REASON: CuPy Raw Kernel voor GPU-side kline lookup
# Dit elimineert CPU-side Python loops en versnelt de mapping 10-100x
_KLINE_LOOKUP_KERNEL = cp.RawKernel(r'''
extern "C" __global__
void kline_lookup(
    const long long* kline_times,   // (M,) sorted kline timestamps in epoch seconds
    const float* kline_highs,       // (M,) highs
    const float* kline_lows,        // (M,) lows
    const long long* signal_times,  // (N,) signal timestamps in epoch seconds
    float* output_prices,           // (N, T, 2) output array [high, low]
    const float* ref_prices,        // (N,) reference prices for missing data
    int M,                          // number of klines
    int N,                          // number of signals
    int T,                          // observation window (minutes)
    int offset_minutes              // offset from signal time (usually 60)
) {
    // Each thread handles one (signal, minute) pair
    int idx = blockDim.x * blockIdx.x + threadIdx.x;
    int signal_idx = idx / T;
    int minute_idx = idx % T;
    
    if (signal_idx >= N) return;
    
    // Target timestamp = signal_time + offset + minute_idx (in minutes -> seconds)
    long long target_time = signal_times[signal_idx] + (offset_minutes + minute_idx) * 60;
    
    // Binary search for target_time in kline_times
    int left = 0;
    int right = M - 1;
    int found_idx = -1;
    
    while (left <= right) {
        int mid = (left + right) / 2;
        if (kline_times[mid] == target_time) {
            found_idx = mid;
            break;
        } else if (kline_times[mid] < target_time) {
            left = mid + 1;
        } else {
            right = mid - 1;
        }
    }
    
    // Output index: (signal_idx, minute_idx, 0/1)
    int out_idx = signal_idx * T * 2 + minute_idx * 2;
    
    if (found_idx >= 0) {
        output_prices[out_idx] = kline_highs[found_idx];
        output_prices[out_idx + 1] = kline_lows[found_idx];
    } else {
        // Fill with reference price if not found
        output_prices[out_idx] = ref_prices[signal_idx];
        output_prices[out_idx + 1] = ref_prices[signal_idx];
    }
}
''', 'kline_lookup')


class GPUBarrierCalculator:
    """
    GPU-versnelde barrier berekening met CuPy.
    
    Verwerkt batches van timestamps parallel op de GPU.
    """
    
    def __init__(self, barriers: List[float], max_obs_min: int = 2880):
        """
        Args:
            barriers: Lijst van barrier levels in ATR units
            max_obs_min: Maximale observation window
        """
        self.barriers = np.array(barriers, dtype=np.float32)
        self.max_obs_min = max_obs_min
        
        # Pre-allocate GPU arrays voor barriers
        self.barriers_gpu = cp.asarray(self.barriers)
        
        logger.info(f"GPUBarrierCalculator: {len(barriers)} barriers, {max_obs_min} min window")
        
        # REASON: Pre-allocated GPU arrays voor kline cache
        self._kline_times_gpu = None
        self._kline_highs_gpu = None
        self._kline_lows_gpu = None
    
    def load_klines_to_gpu(
        self,
        kline_times: np.ndarray,  # (M,) timestamps as epoch seconds (int64)
        kline_highs: np.ndarray,  # (M,) high prices
        kline_lows: np.ndarray    # (M,) low prices
    ) -> int:
        """
        Laad alle klines naar GPU geheugen voor snelle lookup.
        
        REASON: Door klines eenmalig naar GPU te laden, kunnen we de lookup
        volledig op de GPU uitvoeren zonder CPU-GPU data transfer per batch.
        
        Args:
            kline_times: Timestamps als epoch seconds (moet gesorteerd zijn!)
            kline_highs: High prices
            kline_lows: Low prices
            
        Returns:
            Aantal geladen klines
        """
        # REASON: Zorg dat arrays contiguous zijn voor GPU transfer
        self._kline_times_gpu = cp.asarray(kline_times.astype(np.int64), dtype=cp.int64)
        self._kline_highs_gpu = cp.asarray(kline_highs.astype(np.float32), dtype=cp.float32)
        self._kline_lows_gpu = cp.asarray(kline_lows.astype(np.float32), dtype=cp.float32)
        
        logger.info(f"Loaded {len(kline_times)} klines to GPU ({len(kline_times) * 16 / 1024 / 1024:.1f} MB)")
        return len(kline_times)
    
    def calculate_batch_from_gpu_cache(
        self,
        signal_times: np.ndarray,  # (N,) timestamps as epoch seconds
        ref_prices: np.ndarray,    # (N,) reference prices
        atrs: np.ndarray,          # (N,) ATR values
        offset_minutes: int = 60   # Offset from signal time
    ) -> Dict[str, np.ndarray]:
        """
        Bereken barriers met GPU-side kline lookup.
        
        REASON: Combineert kline lookup en barrier berekening op de GPU
        zonder tussentijdse CPU-GPU transfers. Dit is 10-100x sneller
        dan de CPU-side lookup.
        
        Args:
            signal_times: Signal timestamps als epoch seconds
            ref_prices: Reference prices per signal
            atrs: ATR values per signal
            offset_minutes: Minutes offset from signal time (default 60)
            
        Returns:
            Dict met barrier times en extremen
        """
        if self._kline_times_gpu is None:
            raise ValueError("Klines niet geladen op GPU. Roep eerst load_klines_to_gpu() aan.")
        
        N = len(signal_times)
        T = self.max_obs_min
        M = len(self._kline_times_gpu)
        
        # Transfer signal data naar GPU
        signal_times_gpu = cp.asarray(signal_times.astype(np.int64), dtype=cp.int64)
        ref_prices_gpu = cp.asarray(ref_prices.astype(np.float32), dtype=cp.float32)
        
        # Allocate output array op GPU
        output_prices_gpu = cp.zeros((N, T, 2), dtype=cp.float32)
        
        # REASON: Launch kernel met 256 threads per block
        threads_per_block = 256
        total_threads = N * T
        blocks = (total_threads + threads_per_block - 1) // threads_per_block
        
        _KLINE_LOOKUP_KERNEL(
            (blocks,), (threads_per_block,),
            (
                self._kline_times_gpu, self._kline_highs_gpu, self._kline_lows_gpu,
                signal_times_gpu, output_prices_gpu, ref_prices_gpu,
                M, N, T, offset_minutes
            )
        )
        
        # REASON: Nu berekenen we barriers direct op de GPU-prices
        return self.calculate_batch(
            cp.asnumpy(output_prices_gpu),
            ref_prices,
            atrs
        )
    
    def clear_gpu_cache(self):
        """Maak GPU geheugen vrij."""
        self._kline_times_gpu = None
        self._kline_highs_gpu = None
        self._kline_lows_gpu = None
        cp.get_default_memory_pool().free_all_blocks()
        logger.info("GPU kline cache cleared")
    
    def calculate_batch(
        self,
        prices_batch: np.ndarray,  # Shape: (N, T, 2) - [high, low] per timestamp per minuut
        ref_prices: np.ndarray,     # Shape: (N,)
        atrs: np.ndarray            # Shape: (N,)
    ) -> Dict[str, np.ndarray]:
        """
        Bereken barriers voor een batch timestamps op GPU.
        
        Args:
            prices_batch: (N, T, 2) array - [high, low] per timestamp per minuut
            ref_prices: (N,) referentie prijzen
            atrs: (N,) ATR waarden
            
        Returns:
            Dict met arrays voor elke barrier time
        """
        N = len(ref_prices)
        T = prices_batch.shape[1]
        
        # Transfer naar GPU
        prices_gpu = cp.asarray(prices_batch, dtype=cp.float32)
        ref_gpu = cp.asarray(ref_prices, dtype=cp.float32)[:, None]
        atr_gpu = cp.asarray(atrs, dtype=cp.float32)[:, None]
        
        # Extract high/low
        highs = prices_gpu[:, :, 0]  # (N, T)
        lows = prices_gpu[:, :, 1]   # (N, T)
        
        # Normalize naar ATR units
        highs_atr = (highs - ref_gpu) / atr_gpu  # (N, T)
        lows_atr = (lows - ref_gpu) / atr_gpu    # (N, T)
        
        results = {}
        
        # Bereken tijd tot elke UP barrier
        for level in self.barriers:
            # Mask waar high >= level
            up_mask = highs_atr >= level  # (N, T)
            
            # Vind eerste True per rij (argmax geeft eerste True, maar alleen als er een True is)
            has_hit = up_mask.any(axis=1)  # (N,)
            first_idx = cp.argmax(up_mask, axis=1)  # (N,)
            
            # +1 voor minuten (0-indexed -> 1-indexed)
            # -1 voor "niet geraakt"
            time_to = cp.where(has_hit, first_idx + 1, -1)
            
            key = f"up_{int(level * 100):03d}"
            results[key] = cp.asnumpy(time_to)
        
        # Bereken tijd tot elke DOWN barrier
        for level in self.barriers:
            # Mask waar low <= -level
            down_mask = lows_atr <= -level  # (N, T)
            has_hit = down_mask.any(axis=1)
            first_idx = cp.argmax(down_mask, axis=1)
            time_to = cp.where(has_hit, first_idx + 1, -1)
            
            key = f"down_{int(level * 100):03d}"
            results[key] = cp.asnumpy(time_to)
        
        # Bereken extremen
        results['max_up_atr'] = cp.asnumpy(cp.max(highs_atr, axis=1))
        results['max_down_atr'] = cp.asnumpy(cp.min(lows_atr, axis=1))
        results['time_to_max_up'] = cp.asnumpy(cp.argmax(highs_atr, axis=1) + 1)
        results['time_to_max_down'] = cp.asnumpy(cp.argmin(lows_atr, axis=1) + 1)
        
        return results
    
    def determine_first_significant_batch(
        self,
        results: Dict[str, np.ndarray],
        threshold: float = 0.75
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        Bepaal first significant barrier voor hele batch.
        
        Logica:
        1. Zoek welke richting de 'threshold' als eerste raakt.
        2. In die richting, zoek de verste barrier die geraakt werd v贸贸r de opposite threshold.
        """
        threshold_key = f"{int(threshold * 100):03d}"
        up_threshold_key = f"up_{threshold_key}"
        down_threshold_key = f"down_{threshold_key}"
        
        # Haal times op voor de threshold levels
        up_threshold_times = results.get(up_threshold_key)
        down_threshold_times = results.get(down_threshold_key)
        
        if up_threshold_times is None or down_threshold_times is None:
            # Fallback als threshold niet in barriers zit (zou niet mogen)
            N = len(results['max_up_atr'])
            return np.full(N, 'none', dtype='U10'), np.full(N, -1, dtype=np.int16)
            
        N = len(up_threshold_times)
        barrier_names = np.empty(N, dtype='U10')
        barrier_times = np.zeros(N, dtype=np.int16)
        
        # Beschikbare barrier levels (gesorteerd van hoog naar laag voor makkelijk zoeken)
        sorted_levels = sorted(self.barriers, reverse=True)
        
        for i in range(N):
            u_t = up_threshold_times[i] if up_threshold_times[i] > 0 else 99999
            d_t = down_threshold_times[i] if down_threshold_times[i] > 0 else 99999
            
            if u_t == 99999 and d_t == 99999:
                barrier_names[i] = 'none'
                barrier_times[i] = -1
                continue
            
            # Bepaal winnende richting
            if u_t <= d_t:
                direction = 'up'
                opp_t = d_t
                win_t = u_t
            else:
                direction = 'down'
                opp_t = u_t
                win_t = d_t
                
            # Zoek verste barrier geraakt v贸贸r opposite threshold
            found = False
            for level in sorted_levels:
                if level < threshold:
                    continue
                    
                key = f"{direction}_{int(level * 100):03d}"
                times = results.get(key)
                if times is not None and times[i] > 0 and times[i] <= opp_t:
                    barrier_names[i] = key
                    barrier_times[i] = times[i]
                    found = True
                    break
            
            if not found:
                # Fallback naar threshold (zou altijd geraakt moeten zijn)
                barrier_names[i] = f"{direction}_{threshold_key}"
                barrier_times[i] = win_t
                
        return barrier_names, barrier_times
