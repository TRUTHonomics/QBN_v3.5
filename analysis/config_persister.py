# analysis/config_persister.py
"""
Config Persister voor Threshold Optimalisatie.

Verantwoordelijk voor:
- YAML opslag van optimale thresholds
- Backup van huidige configuratie
- Synchronisatie naar database tabellen:
  - qbn.signal_classification
  - qbn.signal_discretization
  - qbn.signal_weights
  - qbn.threshold_config (nieuw)

REASON: Na YAML-write wordt automatisch db_sync aangeroepen om de database
synchroon te houden met de lokale configuratie. De YAMLs staan nu lokaal
in /app/kfl_backend_config/ (niet meer op Samba mount).
"""

import logging
import shutil
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional
import numpy as np
import yaml

from database.db import get_cursor
from core.config_defaults import (
    DEFAULT_COMPOSITE_NEUTRAL_BAND,
    DEFAULT_COMPOSITE_STRONG_THRESHOLD,
    DEFAULT_ALIGNMENT_HIGH_THRESHOLD,
    DEFAULT_ALIGNMENT_LOW_THRESHOLD
)

# REASON: Add custom representer for numpy types to prevent !!python/object tags in YAML
def numpy_representer(dumper, data):
    return dumper.represent_float(float(data)) if isinstance(data, (np.float32, np.float64)) else dumper.represent_int(int(data))

yaml.add_multi_representer(np.floating, numpy_representer)
yaml.add_multi_representer(np.integer, numpy_representer)

# REASON: Import db_sync voor automatische synchronisatie na YAML-write
sys.path.insert(0, str(Path(__file__).parent.parent))
try:
    from scripts.db_sync import sync_discretization as db_sync_discretization
    DB_SYNC_AVAILABLE = True
except ImportError:
    DB_SYNC_AVAILABLE = False

logger = logging.getLogger(__name__)


class ConfigPersister:
    """
    Persistentie laag voor threshold configuraties.
    
    Ondersteunt:
    - YAML opslag met metadata
    - Automatische backup voor wijzigingen
    - Database synchronisatie
    - Dry-run mode voor preview
    - Rollback naar backup
    """
    
    def __init__(self, config_dir: Path = None, run_id: str = None):
        self.config_dir = config_dir or Path('config')
        self.backup_dir = Path('_backup/thresholds')
        self.run_id = run_id
        
    def save_to_yaml(self, results: Dict[str, Any], output_path: Path = None) -> Path:
        """
        Sla analyse resultaten op naar YAML.
        
        Args:
            results: Dict met analyse resultaten per horizon
            output_path: Optioneel custom pad
            
        Returns:
            Path naar opgeslagen YAML bestand
        """
        output_path = output_path or self.config_dir / 'optimal_thresholds.yaml'
        
        # Als het doelbestand 'discretization.yaml' heet, gebruiken we de merge logica
        if output_path.name == 'discretization.yaml':
            return self.merge_to_discretization(results, output_path)
            
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Backup bestaand bestand indien aanwezig
        if output_path.exists():
            self._create_backup(output_path)
        
        # Build YAML structure
        yaml_data = self._build_yaml_structure(results)
        
        # Write met header comment
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("# Optimal Thresholds for QBN v3 Composites\n")
            f.write(f"# Auto-generated by run_threshold_analysis.py\n")
            f.write(f"# Generated: {datetime.now().isoformat()}\n")
            f.write(f"# Asset: {results.get('asset_id', 'unknown')}\n")
            f.write("#\n")
            f.write("# WARNING: Do not edit manually unless you know what you're doing.\n")
            f.write("# Use --apply-results to sync changes to the database.\n")
            f.write("#\n\n")
            yaml.dump(yaml_data, f, default_flow_style=False, sort_keys=False, allow_unicode=True)
        
        logger.info(f"Saved optimal thresholds to {output_path}")
        
        # REASON: Automatisch database synchroniseren na YAML-write
        self._trigger_db_sync(output_path)
        
        return output_path

    def merge_to_discretization(self, results: Dict[str, Any], yaml_path: Path) -> Path:
        """
        Merge de nieuwe thresholds in een bestaand discretization.yaml bestand.
        Behoudt bestaande indicator thresholds.
        """
        if not yaml_path.exists():
            # REASON: Direct opslaan zonder recursieve call naar save_to_yaml.
            logger.warning(f"Target path {yaml_path} does not exist. Creating new file.")
            yaml_data = self._build_yaml_structure(results)
            yaml_path.parent.mkdir(parents=True, exist_ok=True)
            with open(yaml_path, 'w', encoding='utf-8') as f:
                f.write("# Optimal Thresholds for QBN v3 Composites\n")
                f.write(f"# Auto-generated by run_threshold_analysis.py\n")
                yaml.dump(yaml_data, f, default_flow_style=False, sort_keys=False, allow_unicode=True)
            
            # REASON: Ook db_sync triggeren voor nieuw aangemaakt bestand
            self._trigger_db_sync(yaml_path)
            return yaml_path

        # Backup
        self._create_backup(yaml_path)

        # Lees bestaande data
        with open(yaml_path, 'r', encoding='utf-8') as f:
            existing_data = yaml.safe_load(f) or {}

        # Bouw nieuwe data structure
        new_data = self._build_yaml_structure(results)

        # Merge: voeg 'composites' en 'alignment' toe onder de horizons
        if 'horizons' not in existing_data:
            existing_data['horizons'] = {}

        for horizon, data in new_data.get('horizons', {}).items():
            if horizon not in existing_data['horizons']:
                existing_data['horizons'][horizon] = {}
            
            # Update specifieke velden
            existing_data['horizons'][horizon]['composite_thresholds'] = data.get('composite_thresholds')
            existing_data['horizons'][horizon]['alignment_thresholds'] = data.get('alignment_thresholds')
            existing_data['horizons'][horizon]['signal_weights'] = data.get('signal_weights')

        # Update metadata
        if 'metadata' not in existing_data:
            existing_data['metadata'] = {}
        
        existing_data['metadata']['last_threshold_update'] = datetime.now().isoformat()
        existing_data['metadata']['optimized_asset_id'] = results.get('asset_id')

        # Schrijf terug
        with open(yaml_path, 'w', encoding='utf-8') as f:
            f.write("# =============================================================================\n")
            f.write("# Discretization Thresholds Configuration (Merged with QBN v3 Optimal results)\n")
            f.write("# =============================================================================\n\n")
            yaml.dump(existing_data, f, default_flow_style=False, sort_keys=False, allow_unicode=True)

        logger.info(f"Merged optimal thresholds into {yaml_path}")
        
        # REASON: Automatisch database synchroniseren na YAML-write
        self._trigger_db_sync(yaml_path)
        
        return yaml_path
    
    def _trigger_db_sync(self, yaml_path: Path):
        """
        Trigger database synchronisatie na YAML-write.
        
        REASON: De database moet synchroon lopen met de lokale YAML configuraties.
        Dit voorkomt inconsistenties tussen containers.
        """
        # Alleen sync triggeren als het om de discretization.yaml gaat
        if yaml_path.name != 'discretization.yaml':
            return
            
        if not DB_SYNC_AVAILABLE:
            logger.warning("db_sync module not available - skipping database synchronization. "
                          "Run 'python scripts/db_sync.py' manually to sync.")
            return
        
        try:
            logger.info("Triggering database synchronization after YAML write...")
            db_sync_discretization()
            logger.info("Database synchronization completed successfully")
        except Exception as e:
            logger.error(f"Database synchronization failed: {e}")
            logger.warning("The YAML file has been updated, but the database may be out of sync. "
                          "Run 'python scripts/db_sync.py' manually to fix.")
    
    def _build_yaml_structure(self, results: Dict) -> Dict:
        """Bouw YAML structuur uit analyse resultaten."""
        yaml_data = {
            'horizons': {},
            'metadata': {
                'asset_id': results.get('asset_id'),
                'lookback_days': results.get('lookback_days'),
                'analysis_timestamp': results.get('analysis_timestamp'),
                'samples_used': 0
            }
        }
        
        targets = ['leading', 'coincident', 'confirming']
        
        for horizon, method_results in results.get('horizons', {}).items():
            horizon_data = {
                'composite_thresholds': {},
                'alignment_thresholds': {},
                'signal_weights': {}
            }
            
            # REASON: Haal multivariate resultaten op (target='all')
            cart_all = method_results.get('cart_all')
            logreg_all = method_results.get('logreg_all')
            
            for target in targets:
                # MI Grid -> composite thresholds per target
                mi_key = f"mi_{target}"
                if mi_key in method_results and 'error' not in method_results[mi_key]:
                    mi = method_results[mi_key]
                    # v3.5: Asymmetrische thresholds (bull/bear). Fallback naar legacy velden indien niet aanwezig.
                    bull_nb = mi.get('optimal_bullish_neutral_band') or mi.get('optimal_neutral_band', DEFAULT_COMPOSITE_NEUTRAL_BAND)
                    bear_nb = mi.get('optimal_bearish_neutral_band') or mi.get('optimal_neutral_band', DEFAULT_COMPOSITE_NEUTRAL_BAND)
                    bull_st = mi.get('optimal_bullish_strong_threshold') or mi.get('optimal_strong_threshold', DEFAULT_COMPOSITE_STRONG_THRESHOLD)
                    bear_st = mi.get('optimal_bearish_strong_threshold') or mi.get('optimal_strong_threshold', DEFAULT_COMPOSITE_STRONG_THRESHOLD)

                    # Legacy compat: neutral_band/strong_threshold als envelope
                    legacy_nb = max(float(bull_nb), float(bear_nb))
                    legacy_st = max(float(bull_st), float(bear_st))

                    horizon_data['composite_thresholds'][f"{target}_composite"] = {
                        # Legacy keys (blijven bestaan voor backwards compat)
                        'neutral_band': legacy_nb,
                        'strong_threshold': legacy_st,
                        # New asymmetric keys
                        'bullish_neutral_band': float(bull_nb),
                        'bullish_strong_threshold': float(bull_st),
                        'bearish_neutral_band': float(bear_nb),
                        'bearish_strong_threshold': float(bear_st),
                        'source': 'MI Grid Search',
                        'mi_score': mi.get('score', 0)
                    }
                    
                    # Update samples count
                    meta = mi.get('metadata', {})
                    total_samples = meta.get('train_samples', 0) + meta.get('test_samples', 0)
                    yaml_data['metadata']['samples_used'] = max(
                        yaml_data['metadata']['samples_used'],
                        total_samples
                    )
                else:
                    # Fallback naar defaults als MI niet beschikbaar is
                    horizon_data['composite_thresholds'][f"{target}_composite"] = {
                        'neutral_band': DEFAULT_COMPOSITE_NEUTRAL_BAND,
                        'strong_threshold': DEFAULT_COMPOSITE_STRONG_THRESHOLD,
                        'bullish_neutral_band': DEFAULT_COMPOSITE_NEUTRAL_BAND,
                        'bullish_strong_threshold': DEFAULT_COMPOSITE_STRONG_THRESHOLD,
                        'bearish_neutral_band': DEFAULT_COMPOSITE_NEUTRAL_BAND,
                        'bearish_strong_threshold': DEFAULT_COMPOSITE_STRONG_THRESHOLD,
                        'source': 'default'
                    }

                # CART -> alignment thresholds (extract uit 'cart_all' of 'cart_{target}')
                # REASON: Multivariate CART resultaten verdelen over targets.
                cart = cart_all or method_results.get(f"cart_{target}")
                
                if cart and 'error' not in cart:
                    # Zoek thresholds voor dit target in de multivariate resultaten
                    all_thresh = cart.get('metadata', {}).get('all_thresholds', {})
                    if all_thresh and target in all_thresh:
                        nb = all_thresh[target]['neutral_band']
                        st = all_thresh[target]['strong_threshold']
                    else:
                        # Fallback naar de hoofdfields van het resultaat (legacy of single target)
                        nb = cart.get('optimal_neutral_band', DEFAULT_COMPOSITE_NEUTRAL_BAND)
                        st = cart.get('optimal_strong_threshold', DEFAULT_COMPOSITE_STRONG_THRESHOLD)
                    
                    horizon_data['alignment_thresholds'][f"{target}_alignment"] = {
                        'high_threshold': nb,
                        'low_threshold': -nb,  # Alignment gebruikt neutral_band als high/low grens
                        'source': 'CART Analysis',
                        'cart_score': cart.get('score', 0)
                    }
                else:
                    horizon_data['alignment_thresholds'][f"{target}_alignment"] = {
                        'high_threshold': DEFAULT_ALIGNMENT_HIGH_THRESHOLD,
                        'low_threshold': DEFAULT_ALIGNMENT_LOW_THRESHOLD,
                        'source': 'default'
                    }
            
            # LogReg -> signal weights (extract uit logreg_all)
            logreg = logreg_all or next((v for k, v in method_results.items() if k.startswith('logreg') and 'error' not in v), None)
            if logreg and 'error' not in logreg:
                weights = logreg.get('signal_weights', {})
                
                # Categorize by semantic class
                categorized = {'leading': {}, 'coincident': {}, 'confirming': {}}
                for signal, weight in weights.items():
                    if 'lead' in signal.lower():
                        categorized['leading'][signal] = round(float(weight), 4)
                    elif 'coin' in signal.lower() or 'coincident' in signal.lower():
                        categorized['coincident'][signal] = round(float(weight), 4)
                    else:
                        categorized['confirming'][signal] = round(float(weight), 4)
                
                horizon_data['signal_weights'] = categorized
            
            yaml_data['horizons'][horizon] = horizon_data
        
        return self._clean_data(yaml_data)

    def _clean_data(self, data: Any) -> Any:
        """Recursief opschonen van data voor YAML dump (converteer numpy naar python types)."""
        if isinstance(data, dict):
            return {k: self._clean_data(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._clean_data(v) for v in data]
        elif isinstance(data, (np.float32, np.float64, np.floating)):
            return float(data)
        elif isinstance(data, (np.int32, np.int64, np.integer)):
            return int(data)
        elif isinstance(data, np.ndarray):
            return self._clean_data(data.tolist())
        else:
            return data
    
    def _create_backup(self, file_path: Path):
        """Maak backup van bestaand configuratiebestand."""
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"{file_path.stem}_{timestamp}{file_path.suffix}"
        backup_path = self.backup_dir / backup_name
        
        shutil.copy2(file_path, backup_path)
        logger.info(f"Created backup: {backup_path}")
        
        # Keep only last 10 backups
        backups = sorted(self.backup_dir.glob(f"{file_path.stem}_*{file_path.suffix}"))
        if len(backups) > 10:
            for old_backup in backups[:-10]:
                old_backup.unlink()
                logger.debug(f"Removed old backup: {old_backup}")
    
    def sync_from_yaml(self, yaml_path: Path, dry_run: bool = False):
        """
        Synchroniseer YAML configuratie naar database.
        
        Args:
            yaml_path: Pad naar YAML bestand
            dry_run: Als True, toon wijzigingen zonder uit te voeren
        """
        if not yaml_path.exists():
            raise FileNotFoundError(f"YAML file not found: {yaml_path}")
        
        with open(yaml_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # REASON: asset_id kan als 'asset_id' of 'optimized_asset_id' in metadata staan
        metadata = config.get('metadata', {})
        asset_id = metadata.get('asset_id') or metadata.get('optimized_asset_id')
        if not asset_id:
            raise ValueError("No asset_id or optimized_asset_id found in YAML metadata")
        
        logger.info(f"{'[DRY RUN] ' if dry_run else ''}Syncing config for asset {asset_id}")
        
        # Ensure composite_threshold_config table exists
        if not dry_run:
            self._ensure_composite_threshold_config_table()
        
        # Sync per horizon
        for horizon, data in config.get('horizons', {}).items():
            self._sync_horizon_config(asset_id, horizon, data, dry_run)
        
        logger.info(f"{'[DRY RUN] ' if dry_run else ''}Sync complete")
    
    def _ensure_composite_threshold_config_table(self):
        """Maak qbn.composite_threshold_config tabel indien deze niet bestaat."""
        create_sql = """
        CREATE TABLE IF NOT EXISTS qbn.composite_threshold_config (
            asset_id INTEGER NOT NULL,
            horizon VARCHAR(10) NOT NULL,
            config_type VARCHAR(50) NOT NULL,
            param_name VARCHAR(50) NOT NULL,
            param_value NUMERIC(10,4) NOT NULL,
            source_method VARCHAR(50),
            score NUMERIC(10,6),
            created_at TIMESTAMPTZ DEFAULT NOW(),
            updated_at TIMESTAMPTZ DEFAULT NOW(),
            run_id VARCHAR(50) NOT NULL,
            PRIMARY KEY (asset_id, horizon, config_type, param_name, run_id)
        );
        
        CREATE INDEX IF NOT EXISTS idx_composite_threshold_config_asset 
        ON qbn.composite_threshold_config(asset_id);
        """
        
        with get_cursor(commit=True) as cur:
            cur.execute(create_sql)
        
        logger.debug("Ensured qbn.composite_threshold_config table exists")
    
    def _sync_horizon_config(
        self,
        asset_id: int,
        horizon: str,
        data: Dict,
        dry_run: bool
    ):
        """Synchroniseer configuratie voor een specifieke horizon."""
        
        # 1. Sync composite thresholds (new granular dictionary structure)
        composites = data.get('composite_thresholds', {})
        for config_type, comp in composites.items():
            self._upsert_threshold(
                asset_id, horizon, config_type, 'neutral_band',
                comp.get('neutral_band', DEFAULT_COMPOSITE_NEUTRAL_BAND),
                comp.get('source', 'unknown'),
                comp.get('mi_score'),
                dry_run
            )
            self._upsert_threshold(
                asset_id, horizon, config_type, 'strong_threshold',
                comp.get('strong_threshold', DEFAULT_COMPOSITE_STRONG_THRESHOLD),
                comp.get('source', 'unknown'),
                comp.get('mi_score'),
                dry_run
            )

            # v3.5: Asymmetrische parameters (optioneel aanwezig)
            for pname in [
                'bullish_neutral_band',
                'bullish_strong_threshold',
                'bearish_neutral_band',
                'bearish_strong_threshold',
            ]:
                if pname in comp and comp.get(pname) is not None:
                    self._upsert_threshold(
                        asset_id, horizon, config_type, pname,
                        float(comp[pname]),
                        comp.get('source', 'unknown'),
                        comp.get('mi_score'),
                        dry_run
                    )
        
        # 2. Sync alignment thresholds (new granular dictionary structure)
        alignments = data.get('alignment_thresholds', {})
        for config_type, align in alignments.items():
            self._upsert_threshold(
                asset_id, horizon, config_type, 'high_threshold',
                align.get('high_threshold', DEFAULT_ALIGNMENT_HIGH_THRESHOLD),
                align.get('source', 'unknown'),
                align.get('cart_score'),
                dry_run
            )
            self._upsert_threshold(
                asset_id, horizon, config_type, 'low_threshold',
                align.get('low_threshold', DEFAULT_ALIGNMENT_LOW_THRESHOLD),
                align.get('source', 'unknown'),
                align.get('cart_score'),
                dry_run
            )
        
        # 3. Sync signal weights (naar qbn.signal_weights)
        weights = data.get('signal_weights', {})
        if weights:
            self._sync_signal_weights(asset_id, horizon, weights, dry_run)
    
    def _upsert_threshold(
        self,
        asset_id: int,
        horizon: str,
        config_type: str,
        param_name: str,
        param_value: float,
        source_method: str,
        score: Optional[float],
        dry_run: bool
    ):
        """Insert of update een threshold waarde."""
        if dry_run:
            logger.info(f"  [DRY RUN] UPSERT qbn.composite_threshold_config: "
                       f"asset={asset_id}, horizon={horizon}, "
                       f"{config_type}.{param_name}={param_value}")
            return
        
        upsert_sql = """
        INSERT INTO qbn.composite_threshold_config 
            (asset_id, horizon, config_type, param_name, param_value, source_method, score, run_id, updated_at)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW())
        ON CONFLICT (asset_id, horizon, config_type, param_name, run_id)
        DO UPDATE SET 
            param_value = EXCLUDED.param_value,
            source_method = EXCLUDED.source_method,
            score = EXCLUDED.score,
            updated_at = NOW()
        """
        
        with get_cursor(commit=True) as cur:
            cur.execute(upsert_sql, (
                asset_id, horizon, config_type, param_name,
                param_value, source_method, score, self.run_id
            ))
        
        logger.debug(f"Upserted {config_type}.{param_name}={param_value} for {horizon}")
    
    def _sync_signal_weights(self, asset_id: int, horizon: str, weights: Dict, dry_run: bool):
        """Synchroniseer signaal gewichten naar qbn.signal_weights."""
        # Flatten categorized weights
        flat_weights = {}
        for category, signals in weights.items():
            if isinstance(signals, dict):
                flat_weights.update(signals)
        
        if not flat_weights:
            return
        
        # REASON: Map de generieke feature namen uit de analyse terug naar database signalen.
        # Bijv: 'rsi_oversold' -> 'rsi_oversold_60' voor horizon '1h'.
        suffix_map = {
            '1h': '_60',
            '4h': '_240',
            '1d': '_d'
        }
        suffix = suffix_map.get(horizon, '')
        
        for feature_name, weight in flat_weights.items():
            # Construct DB signal name (bijv. rsi_oversold_60)
            # Uitzondering voor signalen die al een suffix hebben of speciaal zijn
            if any(feature_name.endswith(s) for s in ['_60', '_240', '_d']):
                signal_name = feature_name
            else:
                signal_name = f"{feature_name}{suffix}"

            if dry_run:
                logger.info(f"  [DRY RUN] UPDATE qbn.signal_weights: "
                           f"asset={asset_id}, horizon={horizon}, signal={signal_name}, weight={weight}")
                continue
            
            # Update existing weight
            update_sql = """
                UPDATE qbn.signal_weights 
                SET weight = %s, last_trained_at = NOW(), run_id = %s
                WHERE asset_id = %s AND horizon = %s AND signal_name = %s
            """
            
            with get_cursor(commit=True) as cur:
                cur.execute(update_sql, (weight, self.run_id, asset_id, horizon, signal_name))
                if cur.rowcount > 0:
                    logger.debug(f"Updated weight for {signal_name} ({horizon}): {weight}")
                else:
                    # Als de naam met suffix niet bestaat, probeer zonder suffix (legacy/fallback)
                    cur.execute(update_sql, (weight, self.run_id, asset_id, horizon, feature_name))
                    if cur.rowcount > 0:
                        logger.debug(f"Updated weight for {feature_name} (no suffix) ({horizon}): {weight}")
    
    def rollback(self, backup_name: Optional[str] = None):
        """
        Terugkeren naar een backup configuratie.
        
        Args:
            backup_name: Naam van backup bestand, of None voor meest recente
        """
        if backup_name:
            backup_path = self.backup_dir / backup_name
        else:
            # Meest recente backup
            backups = sorted(self.backup_dir.glob("optimal_thresholds_*.yaml"))
            if not backups:
                raise FileNotFoundError("No backups found")
            backup_path = backups[-1]
        
        if not backup_path.exists():
            raise FileNotFoundError(f"Backup not found: {backup_path}")
        
        target_path = self.config_dir / 'optimal_thresholds.yaml'
        
        # Backup current
        if target_path.exists():
            self._create_backup(target_path)
        
        # Restore
        shutil.copy2(backup_path, target_path)
        logger.info(f"Restored config from {backup_path}")
        
        return target_path
    
    def get_current_thresholds(self, asset_id: int, horizon: str = '1h') -> Dict:
        """
        Haal huidige thresholds uit database.
        
        Returns:
            Dict met huidige threshold waarden
        """
        query = """
        SELECT config_type, param_name, param_value, source_method, score
        FROM qbn.composite_threshold_config
        WHERE asset_id = %s AND horizon = %s
        """
        
        result = {
            'composite': {},
            'alignment': {}
        }
        
        try:
            with get_cursor() as cur:
                cur.execute(query, (asset_id, horizon))
                rows = cur.fetchall()
            
            for row in rows:
                config_type, param_name, param_value, source, score = row
                if config_type in result:
                    result[config_type][param_name] = {
                        'value': float(param_value),
                        'source': source,
                        'score': float(score) if score else None
                    }
        except Exception as e:
            logger.warning(f"Could not fetch thresholds from database: {e}")
        
        return result

